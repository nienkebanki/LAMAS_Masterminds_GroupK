<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>MastersMinds – Theory</title>
  <link rel="stylesheet" href="styles.css?v=1" />
  <script>
    window.MathJax = { tex: { inlineMath: [['$', '$'], ['\\(', '\\)']] } };
  </script>
  <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
<header>
  <div class="title-plate" role="img" aria-label="Mastermind title plate">
    <span class="peg-col left" aria-hidden="true">
      <span class="peg"></span>
      <span class="peg"></span>
      <span class="peg"></span>
    </span>

    <h1 class="plate-text">MASTERSMINDS</h1>

    <span class="peg-col right" aria-hidden="true">
      <span class="peg"></span>
      <span class="peg"></span>
      <span class="peg"></span>
    </span>
  </div>
  <h2>Theory</h2>
  <nav>
    <a href="index.html">Home</a>
    <a href="game.html">Game</a>
    <a class="active" href="theory.html">Theory</a>
    <a href="strategies.html">Strategies</a>
    <a href="experiments.html">Experiments</a>
    <a href="implementation.html">Implementation</a>
    <a href="references.html">References</a>
  </nav>
</header>

<main>
  <section>
    <h2>Theory</h2>

    <h3>Epistemic Logic</h3>
    <p>
      Epistemic logic is a modal logic in which “agent $i$ knows $\varphi$” is written $K_i\varphi$, and
      “agent $i$ considers $\varphi$ possible” is written $M_i\varphi$. Knowledge is interpreted not as a
      psychological state but as a constraint: agent $i$ knows $\varphi$ exactly when $\varphi$ holds in every
      world that $i$ still considers possible. Semantically, a Kripke model consists of a set of possible worlds
      together with, for each agent, an indistinguishability relation that connects worlds that look the same to
      that agent. Evaluating $K_i\varphi$ amounts to checking $\varphi$ in all indistinguishable worlds.
    </p>

    <p>
      To model Master(s)Minds, we treat a world as a full hidden configuration of the game, i.e. a pair
      $(\mathit{code}_A,\mathit{code}_B)$. $A$’s indistinguishability relation connects worlds that agree on
      $A$’s own code (since $A$ knows it) but may differ on $B$’s code; similarly for $B$. Thus each agent’s
      information state is the set of opponent codes they still consider possible. An agent has solved the game
      epistemically when all worlds they consider possible agree on the opponent’s code, that is, when their
      candidate set is a singleton.
    </p>

    <p>
      Besides each agent’s uncertainty about the opponent’s code, we also track what each agent believes the
      opponent considers possible about their own code. For each agent $i$, we maintain a set $T_i$ of codes
      that the opponent still considers possible for $i$’s secret code (as modelled by $i$). This is important
      for analysing information leakage, since $T_i$ is updated whenever $i$ provides feedback.
    </p>

    <h3>Public announcements and updates</h3>
    <p>
      The game dynamics are captured using Dynamic Epistemic Logic. After each guess, a publicly observed outcome
      provides information to both players, and each updates their model accordingly. Public Announcement Logic (PAL)
      describes this process: after a truthful public announcement of $\varphi$, the epistemic model is restricted
      to the worlds in which $\varphi$ holds.
    </p>

    <p>
      In Master(s)Minds, each move produces two feedback values: the Mastermind-style feedback on the opponent’s code
      and the feedback on the player’s own code for that same guess. Together these form a conjunctive public announcement
      eliminating all worlds incompatible with either feedback. Since the announcement is public, both players update, and
      each knows that the other updated as well. This shared updating is what makes the game strategic: a move changes not
      only one’s own knowledge but also the opponent’s knowledge and what the opponent can infer.
    </p>

    <p>
      Because all remaining worlds are treated as equally possible and eliminated deterministically, epistemic uncertainty can
      naturally be measured by Hartley entropy, $H=\log_2|S|$, which counts the number of bits required to specify the remaining
      possible worlds. This uniform-entropy view aligns with S5 knowledge models, where agents have no probabilistic beliefs:
      only sets of indistinguishable worlds.
    </p>

    <h3>Higher-order reasoning and common knowledge</h3>
    <p>
      Because updates are public, Master(s)Minds supports higher-order reasoning. After an outcome, each agent knows not only how
      their own information state changes, but also how the opponent’s information state changes, and that the opponent knows this
      too. This corresponds to nested knowledge operators of the form $K_iK_j\varphi$, and possibly deeper iterations. The original
      MastersMinds literature highlights this as a setting where players may require second-order Theory of Mind reasoning to
      anticipate the opponent’s updates.
    </p>

    <p>
      Publicly observed outcomes also accumulate into a shared history, generating common knowledge: information that everyone knows,
      everyone knows that everyone knows, and so on. This common ground is what allows players to coordinate their reasoning about how
      information flows through the game and how future updates will affect each other’s knowledge.
    </p>
  </section>


</main>

<footer>
  <p>LAMAS · Project Masterminds · Theory</p>
</footer>
</body>
</html>
