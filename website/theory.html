<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>MastersMinds – Theory</title>
  <link rel="stylesheet" href="styles.css?v=1" />
  <script>
    window.MathJax = { tex: { inlineMath: [['$', '$'], ['\\(', '\\)']] } };
  </script>
  <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
<header>
  <div class="title-plate" role="img" aria-label="Mastermind title plate">
    <span class="peg-col left" aria-hidden="true">
      <span class="peg"></span>
      <span class="peg"></span>
      <span class="peg"></span>
    </span>

    <h1 class="plate-text">MASTERSMINDS</h1>

    <span class="peg-col right" aria-hidden="true">
      <span class="peg"></span>
      <span class="peg"></span>
      <span class="peg"></span>
    </span>
  </div>
  <h2>Theory</h2>
  <nav>
    <a href="index.html">Home</a>
    <a href="game.html">Game</a>
    <a class="active" href="theory.html">Theory</a>
    <a href="strategies.html">Strategies</a>
    <a href="experiments.html">Experiments</a>
    <a href="implementation.html">Implementation</a>
    <a href="references.html">References</a>
  </nav>
</header>

<main>
  <section>
    <h2>Epistemic Logic</h2>
    <p>
      Epistemic logic is a modal logic where “agent $i$ knows $\varphi$” is written as $K_i\varphi$, and
      “agent $i$ considers $\varphi$ possible” is written as $M_i\varphi$. We use this framework for MastersMinds.
      The core idea is that knowledge is not a feeling but a constraint: agent $i$ knows $\varphi$ exactly when
      $\varphi$ is true in every situation that $i$ still considers possible. Semantically, a Kripke model is represented
      as a set of possible worlds (states), plus for each agent an indistinguishability relation connecting worlds that look
      the same to that agent. Knowledge is then evaluated by looking at all indistinguishable worlds. This is the backbone
      that lets us talk precisely about what is ruled out, what remains possible, and what becomes known.
    </p>
    <p>
      To model MastersMinds, we treat a world as a full hidden configuration of the game. In the simplest version, that means
      a pair $(\text{codeA}, \text{codeB})$. Player $A$’s relation connects exactly those worlds that agree on $A$’s own code
      (because $A$ knows it) while allowing $B$’s code to vary; similarly for $B$. So each player’s information state is the
      set of opponent codes still compatible with what they have observed. Player $A$ has solved the game when all worlds $A$
      still considers possible agree on $B$’s code, i.e., there is only one remaining candidate for $B$. This is the formal
      version of “the evidence uniquely determines the opponent’s code,” even if the player has not yet typed the exact guess.
    </p>
  </section>

  <section>
    <h2>Public Announcements and Updates</h2>
    <p>
      Dynamic Epistemic Logic is involved in MastersMinds because after each guess, the public outcome provides new information
      and everyone updates. Public Announcement Logic (PAL) captures exactly this kind of information change: after a truthful
      public announcement of $\varphi$, the epistemic model is restricted to the worlds where $\varphi$ holds (incompatible worlds
      are deleted). In MastersMinds, a feedback result functions as a public announcement because it eliminates all worlds (code pairs)
      that would not have produced that feedback. Because the outcome is public, both players perform the update, and each player knows
      the other updated too. This shared updating is exactly why the game becomes strategic: your move changes not only what you learn,
      but also what your opponent can infer.
    </p>
  </section>

  <section>
    <h2>Higher-order Knowledge and Common Knowledge</h2>
    <p>
      Since outcomes are public, MastersMinds naturally produces first-order reasoning but also higher-order reasoning: not only
      “what I know,” but also “what I know you now know,” and so on. Rineke’s paper motivates MastersMinds specifically as a competitive
      setting where players may need (and learn) second-order Theory of Mind, and it connects these orders to nested mental-state reasoning
      that is expressible with nested knowledge operators. A stronger shared-information notion is common knowledge, meaning information that
      everyone knows, everyone knows that everyone knows, and so on. For MastersMinds, the public history of rounds is a natural candidate
      for common ground, and it enables players to anticipate each other’s updates.
    </p>
  </section>

</main>

<footer>
  <p>LAMAS · Project Masterminds · Theory</p>
</footer>
</body>
</html>
